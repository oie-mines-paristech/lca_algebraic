<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.4" />
<title>lca_algebraic.stats API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>lca_algebraic.stats</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import warnings
import random
import seaborn as sns
from SALib.analyze import sobol
from SALib.sample import saltelli, sobol_sequence
from ipywidgets import interact
from matplotlib import pyplot as plt
from sympy import Float, Number
from time import time
from .base_utils import _method_unit, _eprint
from .lca import *
from .lca import _expanded_names_to_names
from .params import _variable_params, _param_registry, FixedParamMode


PARALLEL=False

def _parallel_map(f, items) :
    if PARALLEL :
        with concurrent.futures.ThreadPoolExecutor() as exec:
            return exec.map(f, items)
    else :
        return map(f, items)


def _heatmap(df, title, vmax, ints=False):
    &#39;&#39;&#39; Produce heatmap of a dataframe&#39;&#39;&#39;
    fig, ax = plt.subplots(figsize=(17, 17))
    sns.heatmap(df.transpose(), cmap=&#34;gist_heat_r&#34;, vmax=vmax, annot=True, fmt=&#39;.0f&#39; if ints else &#39;.2f&#39;, square=True)
    plt.title(title, fontsize=20)
    ax.tick_params(axis=&#34;x&#34;, labelsize=18)
    ax.tick_params(axis=&#34;y&#34;, labelsize=18)


def oat_matrix(model, impacts, n=10):
    &#39;&#39;&#39;Generates a heatmap of the incertitude of the model, varying input parameters one a a time.&#39;&#39;&#39;

    # Compile model into lambda functions for fast LCA
    lambdas = preMultiLCAAlgebric(model, impacts)

    required_param_names = _expanded_names_to_names(lambdas[0].expanded_params)
    required_params = {key: _param_registry()[key] for key in required_param_names}
    var_params = _variable_params(required_param_names)


    change = np.zeros((len(var_params), len(impacts)))

    for iparam, param in enumerate(var_params.values()):
        params = {param.name: param.default for param in required_params.values()}

        # Compute range of values for given param
        params[param.name] = param.range(n)

        # Compute LCA
        df = postMultiLCAAlgebric(impacts, lambdas, **params)

        # Compute change
        change[iparam] = (df.max() - df.min()) / df.median() * 100

    # Build final heatmap
    change = pd.DataFrame(change, index=var_params.keys(), columns=[imp[2] for imp in impacts])
    _heatmap(change.transpose(), &#39;Change of impacts per variability of the input parameters (%)&#39;, 100, ints=True)


def _display_tabs(titlesAndContentF):
    &#39;&#39;&#39;Generate tabs&#39;&#39;&#39;
    tabs = []
    titles = []
    for title, content_f in titlesAndContentF:
        titles.append(title)

        tab = widgets.Output()
        with tab:
            content_f()
        tabs.append(tab)

    res = widgets.Tab(children=tabs)
    for i, title in enumerate(titles):
        res.set_title(i, title)
    display(res)


def oat_dasboard(modelOrLambdas, impacts, varying_param: ParamDef, n=10, all_param_names=None):
    &#39;&#39;&#39;
    Analyse the evolution of impacts for a single parameter. The other parameters are set to their default values.

    Parameters
    ----------
    model : activity, or lambdas as precomputed by preMultiLCAAlgebric, for faster computation
    impacts : set of methods
    param: parameter to analyse
    n: number of samples of the parameter

    &#39;&#39;&#39;

    if all_param_names == None:
        all_param_names = _param_registry().keys()

    params = {name: _param_registry()[name].default for name in all_param_names}

    # Compute range of values for given param
    params[varying_param.name] = varying_param.range(n)

    # print(&#34;Params: &#34;, params)

    if isinstance(modelOrLambdas, Activity):
        df = multiLCAAlgebric(modelOrLambdas, impacts, **params)
    else:
        df = postMultiLCAAlgebric(impacts, modelOrLambdas, **params)

    # Add X values in the table
    pname = varying_param.name
    if varying_param.unit:
        pname = &#39;%s [%s]&#39; % (pname, varying_param.unit)
    df.insert(0, pname, varying_param.range(n))
    df = df.set_index(pname)

    def table():
        displayWithExportButton(df)

    def graph():

        with warnings.catch_warnings():
            warnings.simplefilter(&#34;ignore&#34;)

            nb_rows = len(impacts) // 3 + 1

            fig, axes = plt.subplots(figsize=(15, 15))

            axes = df.plot(
                ax=axes, sharex=True, subplots=True,
                layout=(nb_rows, 3),
                # legend=None,
                kind=&#39;line&#39; if varying_param.type == ParamType.FLOAT else &#39;bar&#39;)

            axes = axes.flatten()

            for ax, impact in zip(axes, impacts):
                ax.set_ylim(ymin=0)
                ax.set_ylabel(_method_unit(impact))

            plt.show(fig)

    def change():

        ch = (df.max() - df.min()) / df.median() * 100
        fig, ax = plt.subplots(figsize=(9, 6))
        plt.title(&#39;Relative change for %s&#39; % df.index.name)
        ch.plot(kind=&#39;barh&#39;, rot=30)
        ax.set_xlabel(&#39;Relative change of the median value (%)&#39;)
        plt.tight_layout()
        plt.show(fig)

    _display_tabs([
        (&#34;Graphs&#34;, graph),
        (&#34;Data&#34;, table),
        (&#34;Variation&#34;, change)
    ])


def oat_dashboard_interact(model, methods):
    &#39;&#39;&#39;Interative dashboard, with a dropdown for selecting parameter&#39;&#39;&#39;

    lambdas = preMultiLCAAlgebric(model, methods)

    def process_func(param):
        oat_dasboard(lambdas, methods, _param_registry()[param])

    param_list = _expanded_names_to_names(lambdas[0].expanded_params)
    param_list = list(_variable_params(param_list).keys())

    interact(process_func, param=param_list)


class StochasticMethod :
    SALTELLI = &#34;saltelli&#34;
    RAND = &#34;rand&#34;
    SOBOL=&#34;sobol&#34;


def _stochastics(
        modelOrLambdas, methods, n=1000,
        var_params=None, sample_method=StochasticMethod.SALTELLI,
        **extra_fixed_params):

    params, problem = _generate_random_params(n, sample_method, var_params)

    # Fix other params
    if extra_fixed_params :
        params.update(extra_fixed_params)

    Y = _compute_stochastics(modelOrLambdas, methods , params)

    return problem, params, Y


def _compute_stochastics(modelOrLambdas, methods, params):
    if isinstance(modelOrLambdas, Activity):
        Y = multiLCAAlgebric(modelOrLambdas, methods, **params)
    else:
        Y = postMultiLCAAlgebric(methods, modelOrLambdas, **params)
    return Y

def _generate_random_params(n, sample_method=StochasticMethod.SALTELLI, var_params=None, seed=None):

    &#39;&#39;&#39; Compute stochastic impacts for later analysis of incertitude &#39;&#39;&#39;
    if var_params is None:
        var_params = _variable_params().values()

    if seed is None :
        seed = int(time() * 1000)

    random.seed(seed)

    # Extract variable names
    var_param_names = list([param if isinstance(param, str) else param.name for param in var_params])
    problem = {
        &#39;num_vars&#39;: len(var_param_names),
        &#39;names&#39;: var_param_names,
        &#39;bounds&#39;: [[0, 1]] * len(var_param_names)}
    print(&#34;Generating samples ...&#34;)
    if sample_method == StochasticMethod.SALTELLI:
        X = saltelli.sample(problem, n, calc_second_order=True)
    elif sample_method == StochasticMethod.RAND:
        X = np.random.rand(n, len(var_param_names))
    elif sample_method == StochasticMethod.SOBOL:
        print(&#34;sobol !&#34;)
        X = sobol_sequence.sample(n * (len(var_param_names) * 2 + 2), len(var_param_names))
    # elif sample_method == StochasticMethod.LATIN :
    #    X = latin.sample(problem, n)
    else:
        raise Exception(&#34;Unkown rand method &#34; + sample_method)
    # Map normalized 0-1 random values into real values
    print(&#34;Transforming samples ...&#34;)
    params = dict()
    for i, param_name in enumerate(var_param_names):
        param = _param_registry()[param_name]
        params[param_name] = param.rand(X[:, i]).tolist()

    # Add fixed parameters
    for param in _param_registry().values():
        if param.name not in var_param_names:
            params[param.name] = param.default

    return params, problem


class SobolResults :

    def __init__(self, s1, s2, st, s1_conf=None, s2_conf=None, st_conf=None):
        self.s1 = s1
        self.s2 = s2
        self.st = st
        self.s1_conf = s1_conf
        self.s2_conf = s2_conf
        self.st_conf = st_conf


def _sobols(methods, problem, Y) -&gt; SobolResults :
    &#39;&#39;&#39; Computes sobols indices&#39;&#39;&#39;
    s1 = np.zeros((len(problem[&#39;names&#39;]), len(methods)))
    s1_conf = np.zeros((len(problem[&#39;names&#39;]), len(methods)))
    s2 = np.zeros((len(problem[&#39;names&#39;]), len(problem[&#39;names&#39;]), len(methods)))
    s2_conf = np.zeros((len(problem[&#39;names&#39;]), len(problem[&#39;names&#39;]), len(methods)))
    st = np.zeros((len(problem[&#39;names&#39;]), len(methods)))
    st_conf = np.zeros((len(problem[&#39;names&#39;]), len(methods)))

    def process(args) :
        imethod, method = args

        print(&#34;Processing sobol for &#34; + str(method))
        y = Y[Y.columns[imethod]]
        res = sobol.analyze(problem, y.to_numpy(), calc_second_order=True)
        return imethod, res

    for imethod, res in _parallel_map(process, enumerate(methods)):
        try:
            s1[:, imethod] = res[&#34;S1&#34;]
            s1_conf[:, imethod] = res[&#34;S1_conf&#34;]
            s2_ = np.nan_to_num(res[&#34;S2&#34;])
            s2_conf_ = np.nan_to_num(res[&#34;S2_conf&#34;])
            s2[:, :, imethod] = s2_ + np.transpose(s2_)
            s2_conf[:, :, imethod] = s2_conf_ + np.transpose(s2_conf_)
            st[:, imethod] = res[&#34;ST&#34;]
            st_conf[:, imethod] = res[&#34;ST_conf&#34;]

        except Exception as e:
            _eprint(&#34;Sobol failed on %s&#34; % imethod[2], e)

    return SobolResults(s1, s2, st, s1_conf, s2_conf, st_conf)





def _incer_stochastic_matrix(methods, param_names, Y, st):
    &#39;&#39;&#39; Internal method computing matrix of parameter importance &#39;&#39;&#39;

    def draw(mode):

        if mode == &#39;sobol&#39;:
            data = st
        else:
            # If percent, express result as percentage of standard deviation / mean
            data = np.zeros((len(param_names), len(methods)))
            for i, method in enumerate(methods):
                # Total variance
                var = np.var(Y[Y.columns[i]])
                mean = np.mean(Y[Y.columns[i]])
                if mean != 0:
                    data[:, i] = np.sqrt((st[:, i] * var)) / mean * 100

        df = pd.DataFrame(data, index=param_names, columns=[method_name(method) for method in methods])
        _heatmap(
            df.transpose(),
            title=&#34;Relative deviation of impacts (%)&#34; if mode == &#39;percent&#39; else &#34;Sobol indices (part of variability)&#34;,
            vmax=100 if mode == &#39;percent&#39; else 1,
            ints=mode == &#39;percent&#39;)

    interact(draw, mode=[(&#39;Raw sobol indices (ST)&#39;, &#39;sobol&#39;), (&#39;Deviation (ST) / mean&#39;, &#39;percent&#39;)])


def incer_stochastic_matrix(modelOrLambdas, methods, n=1000, var_params=None):
    &#39;&#39;&#39;
    Method computing matrix of parameter importance

    parameters
    ----------
    var_params: Optional list of parameters to vary.
    By default use all the parameters with distribution not FIXED
    &#39;&#39;&#39;

    problem, _, Y = _stochastics(modelOrLambdas, methods, n, var_params)

    print(&#34;Processing Sobol indices ...&#34;)
    sob = _sobols(methods, problem, Y)

    _incer_stochastic_matrix(methods, problem[&#39;names&#39;], Y, sob.st)


def _incer_stochastic_violin(methods, Y):
    &#39;&#39;&#39; Internal method for computing violin graph of impacts &#39;&#39;&#39;

    nb_rows = math.ceil(len(methods) / 3)
    fig, axes = plt.subplots(nb_rows, 3, figsize=(15, 15), sharex=True)

    for imethod, method, ax in zip(range(len(methods)), methods, axes.flatten()):

        data = Y[Y.columns[imethod]]
        median = np.median(data)
        std = np.std(data)
        mean = np.mean(data)

        #ax.hist(Y[Y.columns[imethod]])
        ax.violinplot(data, showmedians=True)
        ax.title.set_text(method_name(method))
        ax.set_ylim(ymin=0)
        ax.set_ylabel(_method_unit(method))

        # Add text
        textstr = &#39;\n&#39;.join((
            r&#39;$\mu=%.3g$&#39; % (mean,),
            r&#39;$\mathrm{median}=%.3g$&#39; % (median,),
            r&#39;$\sigma=%.3g$&#39; % (std,)))
        props = dict(boxstyle=&#39;round&#39;, facecolor=&#39;wheat&#39;, alpha=0.5)
        ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=10,
                verticalalignment=&#39;top&#39;, bbox=props)



    plt.tick_params(axis=&#39;x&#39;, which=&#39;both&#39;, bottom=False, top=False, labelbottom=False)
    plt.show(fig)


def incer_stochastic_violin(modelOrLambdas, methods, n=1000, var_params=None):
    &#39;&#39;&#39;
    Method for computing violin graph of impacts

    parameters
    ----------
    var_params: Optional list of parameters to vary.
    By default use all the parameters with distribution not FIXED
    &#39;&#39;&#39;

    _, _, Y = _stochastics(modelOrLambdas, methods, n, var_params)

    _incer_stochastic_violin(methods, Y)

_percentiles = [10, 90, 25, 50, 75]
def _incer_stochastic_variations(methods, param_names, Y, sob1):
    &#39;&#39;&#39; Method for computing violin graph of impacts &#39;&#39;&#39;
    method_names = [method_name(method) for method in methods]

    std = np.std(Y)
    mean = np.mean(Y)

    fig = plt.figure(num=None, figsize=(12, 6), dpi=80, facecolor=&#39;w&#39;, edgecolor=&#39;k&#39;)
    ax = plt.gca()
    tab20b = plt.get_cmap(&#39;tab20b&#39;)
    tab20c = plt.get_cmap(&#39;tab20c&#39;)
    ax.set_prop_cycle(&#39;color&#39;, [tab20b(k) if k &lt; 1 else tab20c(k - 1) for k in np.linspace(0, 2, 40)])

    relative_variance_pct = std * std / (mean * mean) * 100
    totplt = plt.bar(np.arange(len(method_names)), relative_variance_pct, 0.8)

    sum = np.zeros(len(methods))

    plots = [totplt[0]]

    for i_param, param_name in enumerate(param_names):

        s1 = sob1[i_param, :]

        curr_bar = s1 * relative_variance_pct
        curr_plt = plt.bar(np.arange(len(method_names)), curr_bar, 0.8, bottom=sum)
        sum += curr_bar
        plots.append(curr_plt[0])

    plt.legend(plots, [&#39;Higher order&#39;] + param_names)
    plt.xticks(np.arange(len(method_names)), method_names, rotation=90)
    plt.title(&#34;variance / mean² (%)&#34;)
    plt.show(fig)

def _incer_stochastic_data(methods, param_names, Y, sob1, sobt):

    &#39;&#39;&#39;Show full stochastic output with sobol indices&#39;&#39;&#39;
    data = np.zeros((len(param_names) * 2 + len(_percentiles) +2, len(methods)))
    data[0, :] = np.mean(Y)
    data[1, :] = np.std(Y)

    for i, percentile in enumerate(_percentiles) :
        data[2 + i, :] = np.percentile(Y, percentile, axis=0)

    for i_param, param_name in enumerate(param_names):
        s1 = sob1[i_param, :]
        data[i_param + 2 + len(_percentiles), :] = s1
        data[i_param + 2 + len(_percentiles) + len(param_names), :] = sobt[i_param, :]

    rows = [&#34;mean&#34;, &#34;std&#34;] + \
           [&#34;p%d&#34; % p for p in _percentiles] + \
           [&#34;Sobol 1(%s)&#34; % param for param in param_names] + \
           [&#34;Sobol T(%s)&#34; % param for param in param_names]

    df = pd.DataFrame(data, index=rows, columns=[method_name(method) for method in methods])
    displayWithExportButton(df)

def incer_stochastic_dashboard(model, methods, n=1000, var_params=None):
    &#39;&#39;&#39; Generates a dashboard with several statistics : matrix of parameter incertitude, violin diagrams, ...

    parameters
    ----------
    var_params: Optional list of parameters to vary.
    By default use all the parameters with distribution not FIXED
    &#39;&#39;&#39;

    problem, _, Y = _stochastics(model, methods, n, var_params)
    param_names = problem[&#39;names&#39;]

    print(&#34;Processing Sobol indices ...&#34;)
    sob = _sobols(methods, problem, Y)

    def violin():
        _incer_stochastic_violin(methods, Y)

    def variation():
        _incer_stochastic_variations(methods, param_names, Y, sob.s1)

    def matrix():
        _incer_stochastic_matrix(methods, problem[&#39;names&#39;], Y, sob.st)

    def data():
        _incer_stochastic_data(methods, problem[&#39;names&#39;], Y, sob.s1, sob.st)

    _display_tabs([
        (&#34;Violin graphs&#34;, violin),
        (&#34;Impact variations&#34;, variation),
        (&#34;Sobol matrix&#34;, matrix),
        (&#34;Data&#34;, data)
    ])


def _round_expr(expr, num_digits):
    &#39;&#39;&#39; Round all number in sympy expression with n digits&#39;&#39;&#39;
    return expr.xreplace({n : Float(n, num_digits) if isinstance(n, Float) else n for n in expr.atoms(Number)})

def sobol_simplify_model(model, methods,
                         min_ratio=0.8, n=10000, var_params=None,
                         fixed_mode = FixedParamMode.MEDIAN,
                         sob=None, num_digits=3) :
    &#39;&#39;&#39;
    Computes Sobol indices and selects main parameters for explaining sensibility of at least &#39;min_ratio&#39;,
    Then generates simplified models for those parameters.

    parameters
    ----------
    min_ratio: [0, 1] minimum amount of first order variation (sum of S1) to explain
    var_params: Optional list of parameters to vary.
    fixed_mode : What to replace minor parameters with : MEDIAN by default
    sob: [optional] Pre-computed sobol indices

    returns
    _______

    List of LambdaWithParamNames, one per impact : with wraps the simplified expression together with the
    list of required parameters and a fast complied lambda function for fast evaluation.
    &#39;&#39;&#39;

    # Default var param names
    if var_params is None :
        var_params = _variable_params().values()

    var_param_names = list([param.name for param in var_params])

    if sob==None :

        problem, _, Y = _stochastics(model, methods, n, var_params)

        print(&#34;Processing Sobol indices ...&#34;)
        sob = _sobols(methods, problem, Y)

    s1, s2 = sob.s1, sob.s2

    res = []

    for imethod, method in enumerate(methods) :

        print(&#34;&gt; Method : &#34;, method_name(method))

        s1_sum = np.sum(s1[:, imethod])
        s2_sum = np.sum(s2[:, :, imethod]) / 2
        print(&#39;S1: &#39;, s1_sum)
        print(&#39;S2: &#39;, s2_sum)
        print(&#39;ST: &#39;, np.sum(sob.st[:, imethod]))

        sum = 0
        sorted_param_indices = list(range(0, len(var_param_names)))
        sorted_param_indices = sorted(sorted_param_indices, key=lambda i : s1[i, imethod], reverse=True)
        selected_params = []
        for iparam, param in enumerate(sorted_param_indices) :

            selected_params.append(var_param_names[param])

            # S1
            sum += s1[param, imethod]

            # S2
            #for iparam2 in range(0, iparam) :
            #    param2 = sorted_param_indices[iparam2]
            #    sum += s2[param, param2, imethod]

            if sum &gt; min_ratio :
                break
        print(&#34;Selected params : &#34;, selected_params, &#34;explains: &#34;, sum)

        fixedParams = [param for param in _param_registry().values() if param.name not in selected_params]

        # Generate simplified model
        simplified_expr = simplifiedModel(
            model,
            [method],
            fixed_mode=fixed_mode,
            extraFixedParams=fixedParams)[0]

        simplified_expr = _round_expr(simplified_expr, num_digits)

        display(simplified_expr)

        # Lambdify the expression
        lambd = LambdaWithParamNames(simplified_expr, params=selected_params)

        res.append(lambd)

    return res


def _text(x, y, val):
    txt = plt.text(x, y, val, fontsize=14)
    txt.set_path_effects([patheffects.withStroke(linewidth=3, foreground=&#39;w&#39;)])


def _hline(x1, x2, y, linewidth=1, linestyle=&#39;solid&#39;):
    ymin, ymax = plt.ylim()
    xmin, xmax = plt.xlim()
    minx = (x1 - xmin) / (xmax - xmin)
    maxx = (x2 - xmin) / (xmax - xmin)
    plt.axhline(ymax * y, color=&#39;k&#39;, xmin=minx, xmax=maxx, linewidth=linewidth, linestyle=linestyle)


def _vline(x, ymin, ymax, linewidth=1, linestyle=&#39;solid&#39;):
    plt.axvline(x, color=&#39;k&#39;, ymin=ymin, ymax=ymax, linewidth=linewidth, linestyle=linestyle)


def _graph(data, method, title, ax,
           unit_overrides=None, box=False, scales=None,
           alpha=1, textboxtop=0.95, textboxright=0.95, color=None):
    def unit(method):
        if unit_overrides and method in unit_overrides:
            return unit_overrides[method]
        else:
            return _method_unit(method)

    if ax is not None:
        plt.sca(ax)
    else:
        ax = plt.gca()

    if method[2] == &#39;total energy kwh&#39;:
        data = 1 / data

    if scales and method in scales:
        data = data * scales[method]

    median = np.median(data)
    std = np.std(data)
    mean = np.mean(data)
    p1 = np.percentile(data, 1)
    p99 = np.percentile(data, 99)
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    median = np.percentile(data, 50)

    min_ylim, max_ylim = plt.ylim()

    if box:

        low = 0.3
        high = 0.5
        mid = (low + high) / 2

        xmin = np.min(data)
        xmax = np.max(data)
        plt.xlim(left=xmin, right=xmax)

        # P1 -&gt; Q1
        _hline(p1, q1, mid, linewidth=3)

        # Q1 -&gt; Q3
        _vline(q1, low, high)
        _hline(q1, q3, low, linewidth=1)
        _hline(q1, q3, high, linewidth=1)
        _vline(q3, low, high)

        # p50
        _vline(mean, low, high, linestyle=&#34;dashed&#34;)
        _vline(median, low, high)

        # Q3 -&gt; p99
        _hline(q3, p99, mid, linewidth=3)

    else:
        args = dict()
        if color:
            args[&#39;color&#39;] = color
        p = plt.hist(data, 200, alpha=alpha, **args)
        xmin, xmax = plt.xlim()

    # Box of text
    median = np.median(data)
    std = np.std(data)
    mean = np.mean(data)
    p1 = np.percentile(data, 1)
    p99 = np.percentile(data, 99)
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    variability = std / mean

    textstr = &#39;\n&#39;.join((
        r&#39;$\mu=%.3g$&#39; % (mean,),
        r&#39;$\mathrm{median}=%.3g$&#39; % (median,),
        r&#39;$\sigma=%.3g$&#39; % (std,),
        r&#39;$\sigma/\mu=%.3g$&#39; % (variability,),
        r&#39;$p1=%.3g$&#39; % (p1,),
        r&#39;$p99=%.3g$&#39; % (p99,)
    ))
    props = dict(boxstyle=&#39;round&#39;, facecolor=&#39;wheat&#39; if not color else color, alpha=0.5)
    ax.text(textboxright, textboxtop, textstr, transform=ax.transAxes, fontsize=12,
            verticalalignment=&#39;top&#39;, ha=&#39;right&#39;, bbox=props)

    # Axes
    ax.set_xlabel(unit(method) + &#34; / kWh&#34;, dict(fontsize=14))
    ax.set_yticks([])
    ax.set_title(title, dict(fontsize=16))


def graphs(
        model, methods,
        Y=None, nb_cols=1, box=False, axes=None, title=None, impact_names=None,
        unit_overrides=None,
        scales=None,
        height=10,
        width=15):
    &#34;&#34;&#34; Show distributions together with statistical outcomes&#34;&#34;&#34;

    if Y is None:
        _, _, Y = _stochastics(model, methods, n=100000, salt=False)

    if axes is None:
        nb_rows = math.ceil(len(methods) / nb_cols)
        fig, axes = plt.subplots(nb_rows, nb_cols, figsize=(width, height * nb_rows))

    if isinstance(axes, np.ndarray):
        axes = axes.flatten()
    else:
        axes = [axes]

    plt.subplots_adjust(hspace=0.4)

    for i, method, ax in zip(range(len(methods)), methods, axes):
        data = Y[Y.columns[i]]
        _graph(data, method,
              title if title else impact_names[method] if impact_names else str(method[2]),
              unit_overrides=unit_overrides, scales=scales,
              ax=ax, box=box)

    for i in range(0, -len(methods) % nb_cols):
        ax = axes.flatten()[-(i + 1)]
        ax.axis(&#34;off&#34;)

    return Y


def compare_simplified(model, methods, simpl_lambdas, box=False, nb_cols=2, impact_names=None):
    &#39;&#39;&#39;
    Compare distribution of simplified model with full model
    &#39;&#39;&#39;

    # Raw model
    lambdas = preMultiLCAAlgebric(model, methods)

    nb_rows = math.ceil(len(methods) / nb_cols)
    fig, axes = plt.subplots(nb_rows, nb_cols, figsize=(20, 10 * nb_rows))

    plt.subplots_adjust(hspace=0.4)

    colors = plt.rcParams[&#34;axes.prop_cycle&#34;].by_key()[&#34;color&#34;]

    for i, lambd, simpl_lambd, method, ax in zip(range(len(methods)), lambdas, simpl_lambdas, methods, axes.flatten()):
        params, _ = _generate_random_params(100000, sample_method=StochasticMethod.RAND)

        # Run  Monte Carlo on full model
        Y1 = _compute_stochastics([lambd], [method], params)
        d1 = Y1[Y1.columns[0]]

        # Run monte carlo of simplified model
        Y2 = _compute_stochastics([simpl_lambd], [method], params)
        d2 = Y2[Y2.columns[0]]

        r_value = r_squared(Y1, Y2)

        title = impact_names[method] if impact_names else method[0]

        _graph(d1, method, title, ax=ax, box=box, alpha=0.6, color=colors[0])
        _graph(d2, method, title, ax=ax, box=box, alpha=0.6, textboxright=0.6, color=colors[1])

        ax.text(0.9, 0.65, &#34;R² : %0.3g&#34; % r_value, transform=ax.transAxes, fontsize=14,
                verticalalignment=&#39;top&#39;, ha=&#39;right&#39;)


    # Hide missing graphs
    for i in range(0, -len(methods) % nb_cols):
        ax = axes.flatten()[-(i + 1)]
        ax.axis(&#34;off&#34;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="lca_algebraic.stats.compare_simplified"><code class="name flex">
<span>def <span class="ident">compare_simplified</span></span>(<span>model, methods, simpl_lambdas, box=False, nb_cols=2, impact_names=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Compare distribution of simplified model with full model</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compare_simplified(model, methods, simpl_lambdas, box=False, nb_cols=2, impact_names=None):
    &#39;&#39;&#39;
    Compare distribution of simplified model with full model
    &#39;&#39;&#39;

    # Raw model
    lambdas = preMultiLCAAlgebric(model, methods)

    nb_rows = math.ceil(len(methods) / nb_cols)
    fig, axes = plt.subplots(nb_rows, nb_cols, figsize=(20, 10 * nb_rows))

    plt.subplots_adjust(hspace=0.4)

    colors = plt.rcParams[&#34;axes.prop_cycle&#34;].by_key()[&#34;color&#34;]

    for i, lambd, simpl_lambd, method, ax in zip(range(len(methods)), lambdas, simpl_lambdas, methods, axes.flatten()):
        params, _ = _generate_random_params(100000, sample_method=StochasticMethod.RAND)

        # Run  Monte Carlo on full model
        Y1 = _compute_stochastics([lambd], [method], params)
        d1 = Y1[Y1.columns[0]]

        # Run monte carlo of simplified model
        Y2 = _compute_stochastics([simpl_lambd], [method], params)
        d2 = Y2[Y2.columns[0]]

        r_value = r_squared(Y1, Y2)

        title = impact_names[method] if impact_names else method[0]

        _graph(d1, method, title, ax=ax, box=box, alpha=0.6, color=colors[0])
        _graph(d2, method, title, ax=ax, box=box, alpha=0.6, textboxright=0.6, color=colors[1])

        ax.text(0.9, 0.65, &#34;R² : %0.3g&#34; % r_value, transform=ax.transAxes, fontsize=14,
                verticalalignment=&#39;top&#39;, ha=&#39;right&#39;)


    # Hide missing graphs
    for i in range(0, -len(methods) % nb_cols):
        ax = axes.flatten()[-(i + 1)]
        ax.axis(&#34;off&#34;)</code></pre>
</details>
</dd>
<dt id="lca_algebraic.stats.graphs"><code class="name flex">
<span>def <span class="ident">graphs</span></span>(<span>model, methods, Y=None, nb_cols=1, box=False, axes=None, title=None, impact_names=None, unit_overrides=None, scales=None, height=10, width=15)</span>
</code></dt>
<dd>
<section class="desc"><p>Show distributions together with statistical outcomes</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def graphs(
        model, methods,
        Y=None, nb_cols=1, box=False, axes=None, title=None, impact_names=None,
        unit_overrides=None,
        scales=None,
        height=10,
        width=15):
    &#34;&#34;&#34; Show distributions together with statistical outcomes&#34;&#34;&#34;

    if Y is None:
        _, _, Y = _stochastics(model, methods, n=100000, salt=False)

    if axes is None:
        nb_rows = math.ceil(len(methods) / nb_cols)
        fig, axes = plt.subplots(nb_rows, nb_cols, figsize=(width, height * nb_rows))

    if isinstance(axes, np.ndarray):
        axes = axes.flatten()
    else:
        axes = [axes]

    plt.subplots_adjust(hspace=0.4)

    for i, method, ax in zip(range(len(methods)), methods, axes):
        data = Y[Y.columns[i]]
        _graph(data, method,
              title if title else impact_names[method] if impact_names else str(method[2]),
              unit_overrides=unit_overrides, scales=scales,
              ax=ax, box=box)

    for i in range(0, -len(methods) % nb_cols):
        ax = axes.flatten()[-(i + 1)]
        ax.axis(&#34;off&#34;)

    return Y</code></pre>
</details>
</dd>
<dt id="lca_algebraic.stats.incer_stochastic_dashboard"><code class="name flex">
<span>def <span class="ident">incer_stochastic_dashboard</span></span>(<span>model, methods, n=1000, var_params=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a dashboard with several statistics : matrix of parameter incertitude, violin diagrams, &hellip;</p>
<h2 id="parameters">parameters</h2>
<p>var_params: Optional list of parameters to vary.
By default use all the parameters with distribution not FIXED</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def incer_stochastic_dashboard(model, methods, n=1000, var_params=None):
    &#39;&#39;&#39; Generates a dashboard with several statistics : matrix of parameter incertitude, violin diagrams, ...

    parameters
    ----------
    var_params: Optional list of parameters to vary.
    By default use all the parameters with distribution not FIXED
    &#39;&#39;&#39;

    problem, _, Y = _stochastics(model, methods, n, var_params)
    param_names = problem[&#39;names&#39;]

    print(&#34;Processing Sobol indices ...&#34;)
    sob = _sobols(methods, problem, Y)

    def violin():
        _incer_stochastic_violin(methods, Y)

    def variation():
        _incer_stochastic_variations(methods, param_names, Y, sob.s1)

    def matrix():
        _incer_stochastic_matrix(methods, problem[&#39;names&#39;], Y, sob.st)

    def data():
        _incer_stochastic_data(methods, problem[&#39;names&#39;], Y, sob.s1, sob.st)

    _display_tabs([
        (&#34;Violin graphs&#34;, violin),
        (&#34;Impact variations&#34;, variation),
        (&#34;Sobol matrix&#34;, matrix),
        (&#34;Data&#34;, data)
    ])</code></pre>
</details>
</dd>
<dt id="lca_algebraic.stats.incer_stochastic_matrix"><code class="name flex">
<span>def <span class="ident">incer_stochastic_matrix</span></span>(<span>modelOrLambdas, methods, n=1000, var_params=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Method computing matrix of parameter importance</p>
<h2 id="parameters">parameters</h2>
<p>var_params: Optional list of parameters to vary.
By default use all the parameters with distribution not FIXED</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def incer_stochastic_matrix(modelOrLambdas, methods, n=1000, var_params=None):
    &#39;&#39;&#39;
    Method computing matrix of parameter importance

    parameters
    ----------
    var_params: Optional list of parameters to vary.
    By default use all the parameters with distribution not FIXED
    &#39;&#39;&#39;

    problem, _, Y = _stochastics(modelOrLambdas, methods, n, var_params)

    print(&#34;Processing Sobol indices ...&#34;)
    sob = _sobols(methods, problem, Y)

    _incer_stochastic_matrix(methods, problem[&#39;names&#39;], Y, sob.st)</code></pre>
</details>
</dd>
<dt id="lca_algebraic.stats.incer_stochastic_violin"><code class="name flex">
<span>def <span class="ident">incer_stochastic_violin</span></span>(<span>modelOrLambdas, methods, n=1000, var_params=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Method for computing violin graph of impacts</p>
<h2 id="parameters">parameters</h2>
<p>var_params: Optional list of parameters to vary.
By default use all the parameters with distribution not FIXED</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def incer_stochastic_violin(modelOrLambdas, methods, n=1000, var_params=None):
    &#39;&#39;&#39;
    Method for computing violin graph of impacts

    parameters
    ----------
    var_params: Optional list of parameters to vary.
    By default use all the parameters with distribution not FIXED
    &#39;&#39;&#39;

    _, _, Y = _stochastics(modelOrLambdas, methods, n, var_params)

    _incer_stochastic_violin(methods, Y)</code></pre>
</details>
</dd>
<dt id="lca_algebraic.stats.oat_dasboard"><code class="name flex">
<span>def <span class="ident">oat_dasboard</span></span>(<span>modelOrLambdas, impacts, varying_param, n=10, all_param_names=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Analyse the evolution of impacts for a single parameter. The other parameters are set to their default values.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>activity</code>, or <code>lambdas</code> <code>as</code> <code>precomputed</code> <code>by</code> <code>preMultiLCAAlgebric</code>, <code>for</code> <code>faster</code> <code>computation</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>impacts</code></strong> :&ensp;<code>set</code> of <code>methods</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>param</code></strong> :&ensp;<code>parameter</code> <code>to</code> <code>analyse</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>number</code> of <code>samples</code> of <code>the</code> <code>parameter</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def oat_dasboard(modelOrLambdas, impacts, varying_param: ParamDef, n=10, all_param_names=None):
    &#39;&#39;&#39;
    Analyse the evolution of impacts for a single parameter. The other parameters are set to their default values.

    Parameters
    ----------
    model : activity, or lambdas as precomputed by preMultiLCAAlgebric, for faster computation
    impacts : set of methods
    param: parameter to analyse
    n: number of samples of the parameter

    &#39;&#39;&#39;

    if all_param_names == None:
        all_param_names = _param_registry().keys()

    params = {name: _param_registry()[name].default for name in all_param_names}

    # Compute range of values for given param
    params[varying_param.name] = varying_param.range(n)

    # print(&#34;Params: &#34;, params)

    if isinstance(modelOrLambdas, Activity):
        df = multiLCAAlgebric(modelOrLambdas, impacts, **params)
    else:
        df = postMultiLCAAlgebric(impacts, modelOrLambdas, **params)

    # Add X values in the table
    pname = varying_param.name
    if varying_param.unit:
        pname = &#39;%s [%s]&#39; % (pname, varying_param.unit)
    df.insert(0, pname, varying_param.range(n))
    df = df.set_index(pname)

    def table():
        displayWithExportButton(df)

    def graph():

        with warnings.catch_warnings():
            warnings.simplefilter(&#34;ignore&#34;)

            nb_rows = len(impacts) // 3 + 1

            fig, axes = plt.subplots(figsize=(15, 15))

            axes = df.plot(
                ax=axes, sharex=True, subplots=True,
                layout=(nb_rows, 3),
                # legend=None,
                kind=&#39;line&#39; if varying_param.type == ParamType.FLOAT else &#39;bar&#39;)

            axes = axes.flatten()

            for ax, impact in zip(axes, impacts):
                ax.set_ylim(ymin=0)
                ax.set_ylabel(_method_unit(impact))

            plt.show(fig)

    def change():

        ch = (df.max() - df.min()) / df.median() * 100
        fig, ax = plt.subplots(figsize=(9, 6))
        plt.title(&#39;Relative change for %s&#39; % df.index.name)
        ch.plot(kind=&#39;barh&#39;, rot=30)
        ax.set_xlabel(&#39;Relative change of the median value (%)&#39;)
        plt.tight_layout()
        plt.show(fig)

    _display_tabs([
        (&#34;Graphs&#34;, graph),
        (&#34;Data&#34;, table),
        (&#34;Variation&#34;, change)
    ])</code></pre>
</details>
</dd>
<dt id="lca_algebraic.stats.oat_dashboard_interact"><code class="name flex">
<span>def <span class="ident">oat_dashboard_interact</span></span>(<span>model, methods)</span>
</code></dt>
<dd>
<section class="desc"><p>Interative dashboard, with a dropdown for selecting parameter</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def oat_dashboard_interact(model, methods):
    &#39;&#39;&#39;Interative dashboard, with a dropdown for selecting parameter&#39;&#39;&#39;

    lambdas = preMultiLCAAlgebric(model, methods)

    def process_func(param):
        oat_dasboard(lambdas, methods, _param_registry()[param])

    param_list = _expanded_names_to_names(lambdas[0].expanded_params)
    param_list = list(_variable_params(param_list).keys())

    interact(process_func, param=param_list)</code></pre>
</details>
</dd>
<dt id="lca_algebraic.stats.oat_matrix"><code class="name flex">
<span>def <span class="ident">oat_matrix</span></span>(<span>model, impacts, n=10)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a heatmap of the incertitude of the model, varying input parameters one a a time.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def oat_matrix(model, impacts, n=10):
    &#39;&#39;&#39;Generates a heatmap of the incertitude of the model, varying input parameters one a a time.&#39;&#39;&#39;

    # Compile model into lambda functions for fast LCA
    lambdas = preMultiLCAAlgebric(model, impacts)

    required_param_names = _expanded_names_to_names(lambdas[0].expanded_params)
    required_params = {key: _param_registry()[key] for key in required_param_names}
    var_params = _variable_params(required_param_names)


    change = np.zeros((len(var_params), len(impacts)))

    for iparam, param in enumerate(var_params.values()):
        params = {param.name: param.default for param in required_params.values()}

        # Compute range of values for given param
        params[param.name] = param.range(n)

        # Compute LCA
        df = postMultiLCAAlgebric(impacts, lambdas, **params)

        # Compute change
        change[iparam] = (df.max() - df.min()) / df.median() * 100

    # Build final heatmap
    change = pd.DataFrame(change, index=var_params.keys(), columns=[imp[2] for imp in impacts])
    _heatmap(change.transpose(), &#39;Change of impacts per variability of the input parameters (%)&#39;, 100, ints=True)</code></pre>
</details>
</dd>
<dt id="lca_algebraic.stats.sobol_simplify_model"><code class="name flex">
<span>def <span class="ident">sobol_simplify_model</span></span>(<span>model, methods, min_ratio=0.8, n=10000, var_params=None, fixed_mode='median', sob=None, num_digits=3)</span>
</code></dt>
<dd>
<section class="desc"><p>Computes Sobol indices and selects main parameters for explaining sensibility of at least 'min_ratio',
Then generates simplified models for those parameters.</p>
<h2 id="parameters">parameters</h2>
<dl>
<dt><strong><code>min_ratio</code></strong> :&ensp;[<code>0</code>, <code>1</code>] <code>minimum</code> <code>amount</code> of <code>first</code> <code>order</code> <code>variation</code> (<code>sum</code> of <code>S1</code>) <code>to</code> <code>explain</code></dt>
<dd>&nbsp;</dd>
<dt>var_params: Optional list of parameters to vary.</dt>
<dt><strong><code>fixed_mode</code></strong> :&ensp;<code>What</code> <code>to</code> <code>replace</code> <code>minor</code> <code>parameters</code> <code>with</code> : <code>MEDIAN</code> <code>by</code> default</dt>
<dd>&nbsp;</dd>
<dt><strong><code>sob</code></strong> :&ensp;[optional] <code>Pre</code>-<code>computed</code> <code>sobol</code> <code>indices</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>returns</code></strong></dt>
<dd>&nbsp;</dd>
<dt><strong><code>_______</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<p>List of LambdaWithParamNames, one per impact : with wraps the simplified expression together with the
list of required parameters and a fast complied lambda function for fast evaluation.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sobol_simplify_model(model, methods,
                         min_ratio=0.8, n=10000, var_params=None,
                         fixed_mode = FixedParamMode.MEDIAN,
                         sob=None, num_digits=3) :
    &#39;&#39;&#39;
    Computes Sobol indices and selects main parameters for explaining sensibility of at least &#39;min_ratio&#39;,
    Then generates simplified models for those parameters.

    parameters
    ----------
    min_ratio: [0, 1] minimum amount of first order variation (sum of S1) to explain
    var_params: Optional list of parameters to vary.
    fixed_mode : What to replace minor parameters with : MEDIAN by default
    sob: [optional] Pre-computed sobol indices

    returns
    _______

    List of LambdaWithParamNames, one per impact : with wraps the simplified expression together with the
    list of required parameters and a fast complied lambda function for fast evaluation.
    &#39;&#39;&#39;

    # Default var param names
    if var_params is None :
        var_params = _variable_params().values()

    var_param_names = list([param.name for param in var_params])

    if sob==None :

        problem, _, Y = _stochastics(model, methods, n, var_params)

        print(&#34;Processing Sobol indices ...&#34;)
        sob = _sobols(methods, problem, Y)

    s1, s2 = sob.s1, sob.s2

    res = []

    for imethod, method in enumerate(methods) :

        print(&#34;&gt; Method : &#34;, method_name(method))

        s1_sum = np.sum(s1[:, imethod])
        s2_sum = np.sum(s2[:, :, imethod]) / 2
        print(&#39;S1: &#39;, s1_sum)
        print(&#39;S2: &#39;, s2_sum)
        print(&#39;ST: &#39;, np.sum(sob.st[:, imethod]))

        sum = 0
        sorted_param_indices = list(range(0, len(var_param_names)))
        sorted_param_indices = sorted(sorted_param_indices, key=lambda i : s1[i, imethod], reverse=True)
        selected_params = []
        for iparam, param in enumerate(sorted_param_indices) :

            selected_params.append(var_param_names[param])

            # S1
            sum += s1[param, imethod]

            # S2
            #for iparam2 in range(0, iparam) :
            #    param2 = sorted_param_indices[iparam2]
            #    sum += s2[param, param2, imethod]

            if sum &gt; min_ratio :
                break
        print(&#34;Selected params : &#34;, selected_params, &#34;explains: &#34;, sum)

        fixedParams = [param for param in _param_registry().values() if param.name not in selected_params]

        # Generate simplified model
        simplified_expr = simplifiedModel(
            model,
            [method],
            fixed_mode=fixed_mode,
            extraFixedParams=fixedParams)[0]

        simplified_expr = _round_expr(simplified_expr, num_digits)

        display(simplified_expr)

        # Lambdify the expression
        lambd = LambdaWithParamNames(simplified_expr, params=selected_params)

        res.append(lambd)

    return res</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="lca_algebraic.stats.SobolResults"><code class="flex name class">
<span>class <span class="ident">SobolResults</span></span>
<span>(</span><span>s1, s2, st, s1_conf=None, s2_conf=None, st_conf=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SobolResults :

    def __init__(self, s1, s2, st, s1_conf=None, s2_conf=None, st_conf=None):
        self.s1 = s1
        self.s2 = s2
        self.st = st
        self.s1_conf = s1_conf
        self.s2_conf = s2_conf
        self.st_conf = st_conf</code></pre>
</details>
</dd>
<dt id="lca_algebraic.stats.StochasticMethod"><code class="flex name class">
<span>class <span class="ident">StochasticMethod</span></span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StochasticMethod :
    SALTELLI = &#34;saltelli&#34;
    RAND = &#34;rand&#34;
    SOBOL=&#34;sobol&#34;</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="lca_algebraic.stats.StochasticMethod.RAND"><code class="name">var <span class="ident">RAND</span></code></dt>
<dd>
<section class="desc"><p>str(object='') -&gt; str
str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p>
<p>Create a new string object from the given object. If encoding or
errors is specified, then the object must expose a data buffer
that will be decoded using the given encoding and error handler.
Otherwise, returns the result of object.<strong>str</strong>() (if defined)
or repr(object).
encoding defaults to sys.getdefaultencoding().
errors defaults to 'strict'.</p></section>
</dd>
<dt id="lca_algebraic.stats.StochasticMethod.SALTELLI"><code class="name">var <span class="ident">SALTELLI</span></code></dt>
<dd>
<section class="desc"><p>str(object='') -&gt; str
str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p>
<p>Create a new string object from the given object. If encoding or
errors is specified, then the object must expose a data buffer
that will be decoded using the given encoding and error handler.
Otherwise, returns the result of object.<strong>str</strong>() (if defined)
or repr(object).
encoding defaults to sys.getdefaultencoding().
errors defaults to 'strict'.</p></section>
</dd>
<dt id="lca_algebraic.stats.StochasticMethod.SOBOL"><code class="name">var <span class="ident">SOBOL</span></code></dt>
<dd>
<section class="desc"><p>str(object='') -&gt; str
str(bytes_or_buffer[, encoding[, errors]]) -&gt; str</p>
<p>Create a new string object from the given object. If encoding or
errors is specified, then the object must expose a data buffer
that will be decoded using the given encoding and error handler.
Otherwise, returns the result of object.<strong>str</strong>() (if defined)
or repr(object).
encoding defaults to sys.getdefaultencoding().
errors defaults to 'strict'.</p></section>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="lca_algebraic" href="index.html">lca_algebraic</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="lca_algebraic.stats.compare_simplified" href="#lca_algebraic.stats.compare_simplified">compare_simplified</a></code></li>
<li><code><a title="lca_algebraic.stats.graphs" href="#lca_algebraic.stats.graphs">graphs</a></code></li>
<li><code><a title="lca_algebraic.stats.incer_stochastic_dashboard" href="#lca_algebraic.stats.incer_stochastic_dashboard">incer_stochastic_dashboard</a></code></li>
<li><code><a title="lca_algebraic.stats.incer_stochastic_matrix" href="#lca_algebraic.stats.incer_stochastic_matrix">incer_stochastic_matrix</a></code></li>
<li><code><a title="lca_algebraic.stats.incer_stochastic_violin" href="#lca_algebraic.stats.incer_stochastic_violin">incer_stochastic_violin</a></code></li>
<li><code><a title="lca_algebraic.stats.oat_dasboard" href="#lca_algebraic.stats.oat_dasboard">oat_dasboard</a></code></li>
<li><code><a title="lca_algebraic.stats.oat_dashboard_interact" href="#lca_algebraic.stats.oat_dashboard_interact">oat_dashboard_interact</a></code></li>
<li><code><a title="lca_algebraic.stats.oat_matrix" href="#lca_algebraic.stats.oat_matrix">oat_matrix</a></code></li>
<li><code><a title="lca_algebraic.stats.sobol_simplify_model" href="#lca_algebraic.stats.sobol_simplify_model">sobol_simplify_model</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="lca_algebraic.stats.SobolResults" href="#lca_algebraic.stats.SobolResults">SobolResults</a></code></h4>
</li>
<li>
<h4><code><a title="lca_algebraic.stats.StochasticMethod" href="#lca_algebraic.stats.StochasticMethod">StochasticMethod</a></code></h4>
<ul class="">
<li><code><a title="lca_algebraic.stats.StochasticMethod.RAND" href="#lca_algebraic.stats.StochasticMethod.RAND">RAND</a></code></li>
<li><code><a title="lca_algebraic.stats.StochasticMethod.SALTELLI" href="#lca_algebraic.stats.StochasticMethod.SALTELLI">SALTELLI</a></code></li>
<li><code><a title="lca_algebraic.stats.StochasticMethod.SOBOL" href="#lca_algebraic.stats.StochasticMethod.SOBOL">SOBOL</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.4</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>